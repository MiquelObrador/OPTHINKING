{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BAlqlLzbitsh"
      },
      "outputs": [],
      "source": [
        "#Open the json file\n",
        "import json\n",
        "\n",
        "def read_data(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1islW4OEitsj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gDuF0Zhjitsj"
      },
      "outputs": [],
      "source": [
        "class Dataset_en(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, tokenizer):\n",
        "        self.data = read_data(path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = 512\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx]['text']\n",
        "        label = self.data[idx]['category']\n",
        "        if label == \"CONSPIRACY\":\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, padding='max_length', truncation=True)\n",
        "        item = {key: inputs[key].squeeze(0) for key in inputs}\n",
        "        item['labels'] = torch.tensor(label)\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdYhM004itsk",
        "outputId": "2d1b0227-aea2-40c3-eeec-10570cbf7ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset_en(\"../dataset_en_train.json\", tokenizer)\n",
        "\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuvK8f-6itsk",
        "outputId": "aa5fc1dd-f963-44ab-db54-92201b5361bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3200\n",
            "800\n"
          ]
        }
      ],
      "source": [
        "#Train test split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDOTEaMHPJQq",
        "outputId": "3672d967-a47e-4c06-ad88-68bed984515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7718, 1.4197])\n"
          ]
        }
      ],
      "source": [
        "#Create weights for the classes of the training data\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "labels = [data['labels'].item() for data in train_data]\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2FnGjdt4itsl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "BERT = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "BERT.config.output_hidden_states = True\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9bcg9wIMJk76"
      },
      "outputs": [],
      "source": [
        "class BertLSTMClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert, hidden_size, num_classes):\n",
        "        super(BertLSTMClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.lstm = torch.nn.LSTM(input_size=768, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.linear = torch.nn.Linear(hidden_size*2, num_classes)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.hidden_states\n",
        "        x = hidden_states[-1]\n",
        "        #The lstm should process the sequence of hidden states and use the last hidden state as input to the linear layer\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1QJHGRuJrc-",
        "outputId": "5ecdf486-8850-46e6-cb4b-0bab119e453b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertLSTMClassifier(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (lstm): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BertLSTMClassifier(BERT, hidden_size=256, num_classes=2)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7yM4NVHLA3x",
        "outputId": "582dc344-9322-4d97-8210-e716d7a0b6d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Miquel\\AppData\\Local\\Temp\\ipykernel_16472\\1941504130.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti5zXKG6QmPZ",
        "outputId": "31a7b60b-a177-4924-914a-68348a75cb0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 400/400 [04:48<00:00,  1.38it/s, loss=0.412] \n",
            "Epoch 2: 100%|██████████| 400/400 [04:50<00:00,  1.38it/s, loss=0.816] \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 2\n",
        "\n",
        "model.train()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch+1}\")\n",
        "        loop.set_postfix(loss=loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:21<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8560460652591171\n",
            "Matthews Correlation Coefficient: 0.7875684224774842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Test the model using the f1 score and the mathew correlation coefficient on the test data\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            \n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc}\")\n",
        "\n",
        "#Save the results\n",
        "results = {\n",
        "    \"f1\": f1,\n",
        "    \"mcc\": mcc\n",
        "}\n",
        "\n",
        "with open(\"BERT_LSTM\", 'w') as file:\n",
        "    json.dump(results, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
