{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the data\n",
        "data = pd.read_csv('dataset_en_sentiment.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [-4.228206, -6.7481823, -4.9048667, -4.0775337...\n",
              "1       [-5.1360297, -5.928312, -5.695694, -4.957018, ...\n",
              "2       [-6.5882273, -6.330186, -5.984769, -4.4509463,...\n",
              "3       [-5.051609, -7.2605085, -6.6109424, -4.9246716...\n",
              "4       [-6.1479216, -6.5357866, -6.369592, -4.4938283...\n",
              "                              ...                        \n",
              "3995    [-7.1117854, -6.361661, -5.0720863, -3.2259457...\n",
              "3996    [-5.45811, -6.722521, -5.838917, -4.4321647, -...\n",
              "3997    [-6.074478, -6.4609656, -6.4848986, -5.039374,...\n",
              "3998    [-5.615449, -5.9232645, -5.973674, -4.699154, ...\n",
              "3999    [-6.0916843, -5.4664063, -4.9749045, -2.936697...\n",
              "Name: logits, Length: 4000, dtype: object"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"logits\"] = data[\"logits\"].apply(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\").split(\" \"))\n",
        "\n",
        "#Remove the empty strings\n",
        "data[\"logits\"] = data[\"logits\"].apply(lambda x: [float(i) for i in x if i != \"\"])\n",
        "\n",
        "data[\"logits\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [THIS IS MASSIVE Australian Senator Malcolm Ro...\n",
              "1       [“ I ’m deeply concerned that the push to vacc...\n",
              "2       [2021 They wanted to know your vaccination sta...\n",
              "3       [Anthony Fauci once again defended brutal Chin...\n",
              "4       [Proof has emerged showing that death from Wuh...\n",
              "                              ...                        \n",
              "3995    [Police in Australia are warning that unvaccin...\n",
              "3996    [I personally do n’t believe Putin would set o...\n",
              "3997    [Pfizer lied,  We know that,  \"There s no doub...\n",
              "3998    [It is utterly bizarre and inexplicable Dr,  J...\n",
              "3999    [\"I do nt know about you but I m getting extre...\n",
              "Name: text, Length: 4000, dtype: object"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"text\"] = data[\"text\"].apply(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\",\"))\n",
        "\n",
        "data[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1islW4OEitsj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gDuF0Zhjitsj"
      },
      "outputs": [],
      "source": [
        "class Dataset_en(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[\"text\"][idx]\n",
        "        logits = self.data[\"logits\"][idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdYhM004itsk",
        "outputId": "2d1b0227-aea2-40c3-eeec-10570cbf7ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset_en(\"../dataset_en_train.json\", tokenizer)\n",
        "\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuvK8f-6itsk",
        "outputId": "aa5fc1dd-f963-44ab-db54-92201b5361bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3200\n",
            "800\n"
          ]
        }
      ],
      "source": [
        "#Train test split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDOTEaMHPJQq",
        "outputId": "3672d967-a47e-4c06-ad88-68bed984515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7718, 1.4197])\n"
          ]
        }
      ],
      "source": [
        "#Create weights for the classes of the training data\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "labels = [data['labels'].item() for data in train_data]\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2FnGjdt4itsl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "BERT = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "BERT.config.output_hidden_states = True\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9bcg9wIMJk76"
      },
      "outputs": [],
      "source": [
        "class AttentionPooling(torch.nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionPooling, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.query = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.key = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.value = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "        self.f1 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        #Inputs: (batch_size, seq_len, hidden_size)\n",
        "        query = self.query(inputs)\n",
        "        key = self.key(inputs)\n",
        "        value = self.value(inputs)\n",
        "        \n",
        "        attention_scores = torch.bmm(query, key.transpose(1, 2)) / self.hidden_size**0.5\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "        \n",
        "        context = torch.bmm(attention_weights, value)\n",
        "        \n",
        "        context = self.f1(context)\n",
        "        \n",
        "        pooled_output = context.mean(dim=1)\n",
        "        \n",
        "        return pooled_output\n",
        "\n",
        "class BertClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert, num_classes):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.pooling = AttentionPooling(hidden_size=bert.config.hidden_size)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(bert.config.hidden_size, num_classes)\n",
        "        \n",
        "        self.ffw = torch.nn.Sequential(\n",
        "            torch.nn.Linear(bert.config.hidden_size, bert.config.hidden_size * 4),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(bert.config.hidden_size * 4, bert.config.hidden_size),\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        pooled_output = self.pooling(x)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1QJHGRuJrc-",
        "outputId": "5ecdf486-8850-46e6-cb4b-0bab119e453b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertClassifier(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (pooling): AttentionPooling(\n",
            "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (f1): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (ffw): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BertClassifier(BERT, num_classes=2)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7yM4NVHLA3x",
        "outputId": "582dc344-9322-4d97-8210-e716d7a0b6d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Miquel\\AppData\\Local\\Temp\\ipykernel_8572\\1491795312.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti5zXKG6QmPZ",
        "outputId": "31a7b60b-a177-4924-914a-68348a75cb0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 400/400 [03:11<00:00,  2.08it/s, loss=0.314] \n",
            "100%|██████████| 100/100 [00:15<00:00,  6.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8377358490566038\n",
            "MCC: 0.7596927582631647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 400/400 [03:12<00:00,  2.08it/s, loss=0.0569]\n",
            "100%|██████████| 100/100 [00:16<00:00,  6.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8351648351648352\n",
            "MCC: 0.7795147360812277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 400/400 [03:14<00:00,  2.06it/s, loss=0.318]  \n",
            "100%|██████████| 100/100 [00:16<00:00,  6.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8645640074211504\n",
            "MCC: 0.8000260048539191\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 400/400 [03:15<00:00,  2.05it/s, loss=0.00119] \n",
            "100%|██████████| 100/100 [00:16<00:00,  6.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8765432098765431\n",
            "MCC: 0.823954502802737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 400/400 [03:15<00:00,  2.04it/s, loss=0.000788]\n",
            "100%|██████████| 100/100 [00:16<00:00,  6.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8612836438923396\n",
            "MCC: 0.8030201065650994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "model.train()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "best_mcc = -1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch+1}\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "        \n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, leave=True):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            \n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"MCC: {mcc}\")\n",
        "    \n",
        "    if mcc > best_mcc:\n",
        "        best_mcc = mcc\n",
        "        torch.save(model.state_dict(), \"model_BERT_Attention_Linear.pth\")\n",
        "        \n",
        "    #Save the results each epoch\n",
        "    with open(f\"results_BERT_Attention_Linear_{epoch+1}.txt\", 'w') as file:\n",
        "        file.write(f\"F1 Score: {f1}\\n\")\n",
        "        file.write(f\"MCC: {mcc}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load the best model\n",
        "model.load_state_dict(torch.load(\"model_BERT_Attention.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:15<00:00,  6.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8702928870292888\n",
            "Matthews Correlation Coefficient: 0.8177246968660349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Test the model using the f1 score and the mathew correlation coefficient on the test data\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            \n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc}\")\n",
        "\n",
        "#Save the results\n",
        "results = {\n",
        "    \"f1\": f1,\n",
        "    \"mcc\": mcc\n",
        "}\n",
        "\n",
        "with open(\"BERT_AttentionPooling.json\", 'w') as file:\n",
        "    json.dump(results, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
