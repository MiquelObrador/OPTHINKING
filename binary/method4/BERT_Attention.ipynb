{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BAlqlLzbitsh"
      },
      "outputs": [],
      "source": [
        "#Open the json file\n",
        "import json\n",
        "\n",
        "def read_data(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1islW4OEitsj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Miquel\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_links(text):\n",
        "  lista = text.split()\n",
        "  text = \"\"\n",
        "  checker = True\n",
        "  prev = None\n",
        "  for element in lista:\n",
        "    if element == \"https\" or element == \"www\":\n",
        "      checker = False\n",
        "    elif prev != \"/\" and prev != \"\" and prev != \".\" and prev != \"://\" and prev != \"-\" and element != \"/\" and element != \"\" and element != \".\" and element != \"-\" and element!=\"://\":\n",
        "      checker = True\n",
        "    if checker:\n",
        "      if element not in [\".\", \",\", \":\", \"/\", \";\", \"-\", \"_\", \"'\", '\"', \"|\", \"[\", \"]\", \"+\", \"#\", \"*\", \"(\", \")\"]:\n",
        "        text += \" \"+element\n",
        "    prev = element\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gDuF0Zhjitsj"
      },
      "outputs": [],
      "source": [
        "class Dataset_en(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, tokenizer):\n",
        "        self.data = read_data(path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = 512\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data[idx]['text']\n",
        "        label = self.data[idx]['category']\n",
        "        if label == \"CONSPIRACY\":\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "            \n",
        "        text = remove_links(text)\n",
        "        \n",
        "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, padding='max_length', truncation=True)\n",
        "        item = {key: inputs[key].squeeze(0) for key in inputs}\n",
        "        item['labels'] = torch.tensor(label)\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdYhM004itsk",
        "outputId": "2d1b0227-aea2-40c3-eeec-10570cbf7ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset_en(\"../dataset_en_train.json\", tokenizer)\n",
        "\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuvK8f-6itsk",
        "outputId": "aa5fc1dd-f963-44ab-db54-92201b5361bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3200\n",
            "800\n"
          ]
        }
      ],
      "source": [
        "#Train test split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDOTEaMHPJQq",
        "outputId": "3672d967-a47e-4c06-ad88-68bed984515d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.7718, 1.4197])\n"
          ]
        }
      ],
      "source": [
        "#Create weights for the classes of the training data\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "labels = [data['labels'].item() for data in train_data]\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2FnGjdt4itsl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "BERT = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "BERT.config.output_hidden_states = True\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9bcg9wIMJk76"
      },
      "outputs": [],
      "source": [
        "class AttentionPooling(torch.nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionPooling, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.query = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.key = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.value = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "        self.f1 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        #Inputs: (batch_size, seq_len, hidden_size)\n",
        "        query = self.query(inputs)\n",
        "        key = self.key(inputs)\n",
        "        value = self.value(inputs)\n",
        "        \n",
        "        attention_scores = torch.bmm(query, key.transpose(1, 2)) / self.hidden_size**0.5\n",
        "        attention_weights = self.softmax(attention_scores)\n",
        "        \n",
        "        context = torch.bmm(attention_weights, value)\n",
        "        \n",
        "        context = self.f1(context)\n",
        "        \n",
        "        pooled_output = context.mean(dim=1)\n",
        "        \n",
        "        return pooled_output\n",
        "\n",
        "class BertClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert, num_classes):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.pooling = AttentionPooling(hidden_size=bert.config.hidden_size)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(bert.config.hidden_size, num_classes)\n",
        "        \n",
        "        self.ffw = torch.nn.Sequential(\n",
        "            torch.nn.Linear(bert.config.hidden_size, bert.config.hidden_size * 4),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(bert.config.hidden_size * 4, bert.config.hidden_size),\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        pooled_output = self.pooling(x)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1QJHGRuJrc-",
        "outputId": "5ecdf486-8850-46e6-cb4b-0bab119e453b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertClassifier(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (pooling): AttentionPooling(\n",
            "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (f1): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (ffw): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BertClassifier(BERT, num_classes=2)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7yM4NVHLA3x",
        "outputId": "582dc344-9322-4d97-8210-e716d7a0b6d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Miquel\\AppData\\Local\\Temp\\ipykernel_8132\\1491795312.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti5zXKG6QmPZ",
        "outputId": "31a7b60b-a177-4924-914a-68348a75cb0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 400/400 [03:18<00:00,  2.01it/s, loss=0.000518]\n",
            "100%|██████████| 100/100 [00:16<00:00,  6.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8582089552238807\n",
            "MCC: 0.7903425533886849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 400/400 [03:14<00:00,  2.06it/s, loss=0.00026] \n",
            "100%|██████████| 100/100 [00:16<00:00,  6.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8628230616302187\n",
            "MCC: 0.7999279721499342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 400/400 [03:15<00:00,  2.05it/s, loss=9.07e-5] \n",
            "100%|██████████| 100/100 [00:16<00:00,  6.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8644400785854617\n",
            "MCC: 0.8012874437007889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 400/400 [03:15<00:00,  2.04it/s, loss=0.00069] \n",
            "100%|██████████| 100/100 [00:16<00:00,  6.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8625\n",
            "MCC: 0.8058355850492399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 400/400 [03:15<00:00,  2.05it/s, loss=8.28e-5] \n",
            "100%|██████████| 100/100 [00:16<00:00,  6.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8560311284046692\n",
            "MCC: 0.7882529169379718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "model.train()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "best_mcc = -1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch+1}\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "        \n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, leave=True):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            \n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"MCC: {mcc}\")\n",
        "    \n",
        "    if mcc > best_mcc:\n",
        "        best_mcc = mcc\n",
        "        torch.save(model.state_dict(), \"model_BERT_Attention_NOLINKS.pth\")\n",
        "        \n",
        "    #Save the results each epoch\n",
        "    with open(f\"results_BERT_Attention_NOLINKS_{epoch+1}.txt\", 'w') as file:\n",
        "        file.write(f\"F1 Score: {f1}\\n\")\n",
        "        file.write(f\"MCC: {mcc}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load the best model\n",
        "model.load_state_dict(torch.load(\"model_BERT_Attention.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:15<00:00,  6.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.8702928870292888\n",
            "Matthews Correlation Coefficient: 0.8177246968660349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Test the model using the f1 score and the mathew correlation coefficient on the test data\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            \n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc}\")\n",
        "\n",
        "#Save the results\n",
        "results = {\n",
        "    \"f1\": f1,\n",
        "    \"mcc\": mcc\n",
        "}\n",
        "\n",
        "with open(\"BERT_AttentionPooling.json\", 'w') as file:\n",
        "    json.dump(results, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
